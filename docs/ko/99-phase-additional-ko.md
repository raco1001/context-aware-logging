# Phase Additional — 선제적 지능 (자율 분석 AGENT 추가)

## 목표

회복 탄력적인 데이터 파이프라인에서 자율형 지능 플랫폼으로 전환
Phase 6는 **맥락적 이해(Contextual Understanding)**, **자동화된 합성(Automated Synthesis)**, 그리고 **도메인 특화 전문 지식(Multi-Agent)**을 구상했습니다.

## 전략

Phase 5에서 인프라가 확보되었기에, Phase 6에서는 인간 운영자의 인지 부하를 줄이기 위해 고급 AI 기능을 주제 별로 도입할 수 있다고 생각했습니다.

1.  **심층 패턴 인식**: 클러스터링을 사용하여 로그에서 "알려지지 않은 미지의 정보(Unknown unknowns)"를 찾아냅니다.
2.  **역방향 RAG (브리핑)**: 질문 뿐 만 아니라 시스템의 상태를 먼저 알려줄 수 있는 기능(특정 상황 발생 시 보고서 작성 등).
3.  **특화된 추론**: 도메인 전문 지식(SRE, 보안 등)을 가진 여러 에이전트를 배치하는 건 어떨까요.

---

## 구현 단계

### 1단계: 규칙 기반 사고 집계 (지능화의 가교)

**목표**: 복잡한 클러스터링 알고리즘 없이도 선제적인 탐지 기능을 구현

- **로직**:
  - 5분 슬라이딩 윈도우 내에서 로그를 `(service, route, error.code)` 단위로 그룹화.
  - `count > threshold` (예: 에러 10건) 발생 시 트리거 되는 agent를 구현.
- **LLM 요약**: 수집된 로그 그룹을 LLM에 전달하여 사람이 읽기 쉬운 한 줄 요약을 생성합니다.
  - _예시_: "결제 서비스가 PG사 지연으로 인해 타임아웃 에러가 15% 증가했습니다."

### 2단계: 고급 이벤트 합성 (로그 클러스터링)

**목표**: 단순한 규칙으로는 놓칠 수 있는 패턴을 발견합니다.

- **알고리즘**: `WideEvent` 요약의 벡터 임베딩에 대해 DBSCAN 또는 K-means를 사용합니다.
- **목표**: 서로 다른 에러 메시지라도 동일한 DB 병목 현상을 가리키는 경우처럼, 시맨틱 유사성을 공유하는 이질적인 이벤트들을 그룹화합니다.
- **사고(Incident) 스키마**:
  - `incidentId`, `startTime`, `severity`, `rootCauseAnalysis` (LLM 생성).
  - `relatedTraces`: 클러스터 내의 요청 ID 배열.

### 3단계: 역방향 RAG — 자동화된 시스템 브리핑

**목표**: 시스템 상태와 사고에 대한 "일일 요약(Daily Digest)"보고서를 제공하기

- **합성 엔진**:
  1. 지표(Phase 5에서 수집)를 집계
  2. 사고 클러스터(1단계에서 수집)를 수집
  3. "브리핑 프롬프트"와 함께 LLM에 전달
- **출력**: 다음 내용을 포함하는 자연어 보고서 생성:
  - "오늘의 주요 이슈 Top 3"
  - "이상 징후 트렌드"
  - "리소스 효율성 권장 사항"

### 4단계: 그라운딩 및 신뢰 지표

**목표**: AI 분석가가 정확하고 신뢰할 수 있는지 알려주기

- **검증 지표**:
  - LLM의 주장 중 실제 로그 데이터에 근거한 비율(%).
  - 교차 참조를 통한 환각 탐지.
- **관측 가능성**:
  - 프롬프트 지연 시간 대비 정확도 트레이드오프.
  - 자동 브리핑당 토큰 비용.

### 5단계: 멀티 에이전트 분석가 (플랫폼 단계)

**목표**: 복잡한 도메인 분석을 위한 특화된 에이전트들을 운영하기

- **SRE 에이전트**: 성능 트렌드와 임계값 예측에 집중
- **보안 에이전트**: 비정상적인 접근 패턴과 크리덴셜 스터핑(Credential Stuffing) 탐지에 집중
- **효율성 에이전트**: 처리 시간 지표를 기반으로 코드/인프라 최적화를 제안
- **오케스트레이터(Orchestrator)**: 사용자 질의나 자동 트리거를 가장 관련 있는 에이전트에게 라우팅

---

## 성공 기준

1.  **MTTR 감소**: _예시: 사고 클러스터링을 통해 운영자가 근본 원인을 50% 더 빠르게 식별할 수 있음_
2.  **선제적 가치**: _예시: 수동 알람이 울리기 전에 자동 브리핑이 매주 최소 한 건 이상의 이슈를 강조함_
3.  **신뢰도 평가**: _예시: AI가 생성한 요약이 수동 감사 결과와 비교했을 때 90% 이상의 정확도를 달성함_

## 1. 초고가용성 폴백 및 복구 로직 (Advanced Recovery)

### [기존 2단계 확장] 다계층 폴백 체인 (Tertiary & Last Resort)

- **3순위(Tertiary): Local File**: DB 장애 시 로컬 디스크에 JSON 파일로 기록하여 영속성 확보.
- **최후(Last Resort)**: 디스크 용량 임계치 도달 시 에러 로그 우선순위에 따른 선택적 드롭 전략.

### [기존 3단계] 로컬 버퍼링 및 재시도 (Self-Healing)

- **인메모리 LogBuffer**: 전송 실패한 로그를 메모리 내 큐에 임시 저장.
- **백그라운드 플러시(Flush)**: 장애 복구 감지 시 버퍼의 데이터를 Kafka/DB로 재전송.
- **오버플로우 방지**: 버퍼 사이즈 제한 및 메모리 압박 시 파일 덤프 연동.

## 2. 지능형 자원 통제 (Intelligent Resource Control)

### [기존 5단계 확장] 실시간 동적 샘플링

- **Log Spike 대응**: 시스템 부하나 버퍼 적재량에 따라 '정상' 로그의 샘플링 비율을 실시간으로 하향 조정 (예: 1% -> 0.1%).
- **동적 정책 배포**: 어플리케이션 재배포 없이 설정 서버를 통해 샘플링 정책을 런타임에 업데이트.

## 3. 데이터 정제 및 재처리 (Data Replay)

- **File Dump Replay**: 로컬 파일로 백업된 로그를 시스템 정상화 후 다시 분석 파이프라인으로 밀어넣는 도구 개발.
- **DLQ(Dead Letter Queue) 고도화**: 단순 폴백을 넘어, 실패 원인별 자동 분류 및 재처리 시도 로직 구축.
